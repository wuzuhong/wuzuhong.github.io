function getBlog(){
	return blog = {"content": "# 【消息中间件-Kafka】消息投递的可靠性保证\n\nKafka 消息投递的可靠性保证包括：\n* `at most once`：消息可能会丢失，但不会重复投递。\n* `at least once`：消息绝不会丢失，但可能会重复投递。\n* `exactly once`：每条消息投递一次并且仅投递一次。\n\nKafka 消息投递的可靠性保证默认为`at least once`。 Kafka 可以通过禁用生产者的重试机制和消费者的消费位点提交，来实现`at most once`。 Kafka 提供发布消息的持久性保证和消费消息时的保证来支持`exactly once`。\n\n## 发布消息的持久性保证\n* Kafka 生产者在发布消息后，一旦这个消息被提交到日志并且该消息写入的分区的 Broker 是活动状态，那么该消息就不会丢失。\n* Kafka 生产者如果未能收到消息已提交的响应，那么它可以设置重新发送消息。并且生产者还支持一个幂等投递选项，它保证重发不会导致 Broker 中出现重复条目，为了实现这一点， Broker 为每个生产者分配一个ID，并使用生产者随每个消息一起发送的序列号来删除重复的消息。\n* Kafka 生产者支持使用事务来向多个主题分区发送消息，以达到要么所有消息都成功写入、要么没有消息写入的目的。\n\n## 消费消息时的保证\n如果消费者从未宕机，那么它可以将消费位点存储在内存中。如果消费者宕机，这个主题分区会被另一个消费者接管，新的消费者将需要选择一个合适的消费位点开始消费，但这会产生两个问题：\n* 消费者有可能在消费位点记录之后，数据输出到主题之前，就宕机，那么就会成为`at most once`，当前消息就会丢失。\n* 消费者有可能在消费位点记录之前，数据输出到主题之后，就宕机，那么就会成为`at least once`，当前消息就会重复投递。\n\n消费者的消费位点是作为消息存储在主题中，因此消费者可以在数据输出的主题的相同事务中将消费位点写入 Kafka ，如果事务失败，消费位点将会恢复到原来的值，并且根据其他消费者的“隔离级别”，对数据输出的主题上生成的数据将不可见。在默认的“读取未提交”隔离级别中，所有消息对消费者都是可见的，即使它们是已失败事务的一部分，但在“读取已提交”隔离级别中，消费者将只返回自已提交事务的消息。", "title": "【消息中间件-Kafka】消息投递的可靠性保证"}
}