function getBlog(){
	return blog = {"content": "# 【搜索引擎-Elasticsearch】基于SpringBoot的使用示例\n这里使用的是SpringBoot的`3.0.2`版本。\n\n## 在 pom.xml 中添加依赖\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-elasticsearch</artifactId>\n</dependency>\n```\n\n## 在application.properties中添加配置\n```properties\nspring.elasticsearch.uris=http://127.0.0.1:9200\nspring.elasticsearch.socket-timeout=10s\nspring.elasticsearch.username=elastic\nspring.elasticsearch.password=888888\n```\n\n## 创建文档数据实体测试类\n```java\npublic class DemoDoc {\n    private String id;\n    private String name;\n    private String content;\n    private int num;\n\n    // TODO getter 、 setter 和 constructor\n}\n```\n\n## 使用动态映射创建索引\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@PostMapping(\"/demo\")\npublic Boolean demo() throws IOException {\n    CreateIndexResponse response = elasticsearchClient.indices().create(c ->\n            c.index(\"demo_index\"));\n    return response.acknowledged();\n}\n```\n\n## 使用显式映射创建索引\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@PostMapping(\"/demo\")\npublic Boolean demo() throws IOException {\n    CreateIndexResponse response = elasticsearchClient.indices().create(c ->\n            c.index(\"demo_index\").mappings(m ->\n                    m.dynamic(DynamicMapping.Strict)\n                            .properties(\"id\", Property.of(p -> p.text(TextProperty.of(t -> t.index(true)))))\n                            .properties(\"name\", Property.of(p -> p.text(TextProperty.of(t -> t.index(true)))))\n                            .properties(\"content\", Property.of(p -> p.text(TextProperty.of(t -> t.index(true)))))\n                            .properties(\"num\", Property.of(p -> p.integer(IntegerNumberProperty.of(i -> i.index(true)))))\n            ));\n    return response.acknowledged();\n}\n```\n\n## 删除索引\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@DeleteMapping(\"/demo\")\npublic void demo() throws IOException {\n    elasticsearchClient.indices().delete(c -> c.index(\"demo_index\"));\n}\n```\n\n## 创建文档\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@PostMapping(\"/demo\")\npublic String demo() throws IOException {\n    DemoDoc demoDoc = new DemoDoc(\"aa\", \"bb\", \"cc\", 1);\n    IndexResponse response = elasticsearchClient.index(i -> i.index(\"demo_index\").id(demoDoc.getId()).document(demoDoc));\n    return response.result().toString();\n}\n```\n\n## 删除文档\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@DeleteMapping(\"/demo\")\npublic void demo() throws IOException {\n    elasticsearchClient.delete(i -> i.index(\"demo_index\").id(\"aa\"));\n}\n```\n\n## 根据文档ID查询文档数据\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@GetMapping(\"/demo\")\npublic DemoDoc demo() throws IOException {\n    GetResponse<DemoDoc> response = elasticsearchClient.get(g -> g.index(\"demo_index\").id(\"aa\"), DemoDoc.class);\n    if (response.found()) {\n        return response.source();\n    } else {\n        return null;\n    }\n}\n```\n\n## 使用 match 进行精确匹配\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@GetMapping(\"/demo\")\npublic List<DemoDoc> demo(@RequestParam(\"name\") String name) throws IOException {\n    SearchResponse<DemoDoc> response = elasticsearchClient.search(s -> s\n            .index(\"demo_index\")\n            .query(q -> q\n                    .match(t -> t\n                            .field(\"name\")\n                            .query(name)\n                    )\n            ), DemoDoc.class);\n    return response.hits().hits().stream().map(hit -> hit.source()).collect(Collectors.toList());\n}\n```\n\n## 使用 wildcard 进行模糊匹配\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@GetMapping(\"/demo\")\npublic List<DemoDoc> demo(@RequestParam(\"name\") String name) throws IOException {\n    SearchResponse<DemoDoc> response = elasticsearchClient.search(s -> s\n            .index(\"demo_index\")\n            .query(q -> q\n                    .wildcard(t -> t\n                            .field(\"name\")\n                            .wildcard(\"*\" + name + \"*\"))// 使用 * 来进行模糊匹配\n            ), DemoDoc.class);\n    return response.hits().hits().stream().map(hit -> hit.source()).collect(Collectors.toList());\n}\n```\n\n## 使用 from + size 进行分页查询过滤后的前 1 万条数据，使用 search_after 进行分页查询过滤后的 1 万条之后的数据\n注意： 使用 from 和 size 来实现分页查询时，只能查询过滤后的前 1 万条数据。过滤后的 1 万条之后的数据可以使用 search_after 参数，由于 search_after 参数需要用到上一页返回的 sort 字段数据，所以不能跳转到指定页，只能一页一页的按顺序查，并且在使用 search_after 参数时的 from 字段必须为 0。这里的 sort 字段其实就是排序字段对应的值，所以不管是使用 from 和 size，还是使用 search_after 进行分页时都必须传入排序字段。\n\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@PostMapping(\"/demo\")// 分页查询\npublic Map<String, Object> demo(@RequestParam(\"name\") String name,\n                                @RequestParam(\"currentPage\") Integer currentPage,\n                                @RequestParam(\"pageSize\") Integer pageSize,\n                                @RequestBody List<Long> body) throws IOException {\n    if (currentPage * pageSize <= 10000) {// 使用 from 和 size 来实现分页查询，但是只能查询过滤后的前 1 万条数据\n        SearchResponse<DemoDoc> response = elasticsearchClient.search(s -> s\n                .index(\"demo_index\")\n                .query(q -> q\n                        .wildcard(t -> t\n                                .field(\"name\")\n                                .wildcard(\"*\" + name + \"*\"))\n                )\n                .from((currentPage - 1) * pageSize)\n                .size(pageSize)\n                .sort(SortOptions.of(so -> so.field(f -> f.field(\"num\").order(SortOrder.Asc)))), DemoDoc.class);\n        HitsMetadata<DemoDoc> hits = response.hits();\n        Map<String, Object> result = new HashMap<String, Object>();\n        result.put(\"currentPage\", currentPage);\n        result.put(\"pageSize\", pageSize);\n        result.put(\"data\", hits.hits().stream().map(hit -> hit.source()).collect(Collectors.toList()));\n        result.put(\"total\", hits.total().value());\n        // 返回 sort ，用于下一次查询过滤后的超过前 1 万条数据。这里的 sort 就是当前返回结果的最后一条记录中的排序字段的值，如果有多个排序字段，那么就会有多个\n        List<Long> sort = hits.hits().get(hits.hits().size() - 1).sort().stream().map(e -> e.longValue()).collect(Collectors.toList());\n        result.put(\"sort\", sort);\n        return result;\n    } else {// 使用 search_after 来实现查询过滤后的超过前 1 万条数据\n        SearchResponse<DemoDoc> response = elasticsearchClient.search(s -> s\n                .index(\"demo_index\")\n                .query(q -> q\n                        .wildcard(t -> t\n                                .field(\"name\")\n                                .wildcard(\"*\" + name + \"*\"))\n                )\n                .from(0)// 必须为 0\n                .size(pageSize)\n                .searchAfter(body.stream().map(e -> FieldValue.of(e)).collect(Collectors.toList()))// 使用 searchAfter 参数以及上一次查询返回的 sort 来查询过滤后的超过前 1 万条数据\n                .sort(SortOptions.of(so -> so.field(f -> f.field(\"num\").order(SortOrder.Asc)))), DemoDoc.class);\n        HitsMetadata<DemoDoc> hits = response.hits();\n        Map<String, Object> result = new HashMap<String, Object>();\n        result.put(\"currentPage\", currentPage);\n        result.put(\"pageSize\", pageSize);\n        result.put(\"data\", hits.hits().stream().map(hit -> hit.source()).collect(Collectors.toList()));\n        result.put(\"total\", hits.total().value());\n        List<Long> sort = hits.hits().get(hits.hits().size() - 1).sort().stream().map(e -> e.longValue()).collect(Collectors.toList());\n        result.put(\"sort\", sort);\n        return result;\n    }\n}\n```", "title": "【搜索引擎-Elasticsearch】基于SpringBoot的使用示例"}
}