function getBlog(){
	return blog = {"content": "# 【搜索引擎-Elasticsearch】分词\n文本分析是将文本转换成一系列单词的过程，也叫分词。\n\n比如在使用百度搜索引擎进行检索的时候，输入的一段句子会被分割成不同的关键词来关联查询。\n\n## 安装 IK 中文分词器\nhttps://github.com/medcl/elasticsearch-analysis-ik\n\n## 使用显式映射创建索引并给字段指定分词器\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@PostMapping(\"/demo\")\npublic Boolean demo() throws IOException {\n    CreateIndexResponse response = elasticsearchClient.indices().create(c ->\n            c.index(\"demo_index\").mappings(m ->\n                    m.dynamic(DynamicMapping.Strict)\n                            .properties(\"id\", Property.of(p -> p.text(TextProperty.of(t -> t.index(true)))))\n                            .properties(\"name\", Property.of(p -> p.text(TextProperty.of(t -> t.index(true)))))\n                            .properties(\"content\", Property.of(p -> p.text(TextProperty.of(t -> t.index(true).analyzer(\"ik_max_word\")))))// 指定分词器\n                            .properties(\"num\", Property.of(p -> p.integer(IntegerNumberProperty.of(i -> i.index(true)))))\n            ));\n    return response.acknowledged();\n}\n```\n\n## 使用 match 进行分词匹配\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@GetMapping(\"/demo\")\npublic List<DemoDoc> demo(@RequestParam(\"content\") String content) throws IOException {\n    SearchResponse<DemoDoc> response = elasticsearchClient.search(s -> s\n            .index(\"demo_index\")\n            .query(q -> q\n                    .match(t -> t\n                            .field(\"content\")\n                            .query(content)\n                    )\n            ), DemoDoc.class);\n    return response.hits().hits().stream().map(hit -> hit.source()).collect(Collectors.toList());\n}\n```\n\n## 获取分词结果\n在使用 match 进行分词匹配之后，如果想让返回的记录中高亮匹配的分词，可以通过[获取分词结果](####获取分词结果)来获取需要高亮的分词文字。\n\n```java\n@Autowired\nprivate ElasticsearchClient elasticsearchClient;\n\n@GetMapping(\"/demo\")\npublic List<String> demo(@RequestParam(\"content\") String content) throws IOException {\n    // 获取文本content被分词器转换之后的单词集合\n    AnalyzeResponse response = elasticsearchClient.indices().analyze(AnalyzeRequest.of(a -> a.analyzer(\"ik_max_word\").field(\"content\").text(content)));\n    return response.tokens().stream().map(e -> e.token()).collect(Collectors.toList());\n}\n```", "title": "【搜索引擎-Elasticsearch】分词"}
}